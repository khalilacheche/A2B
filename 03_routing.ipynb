{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Main notebook to run our application (neeeds 4GB of memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import math\n",
    "import pickle\n",
    "from itertools import islice\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType , DoubleType\n",
    "from collections import defaultdict\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import datetime\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. We load the preprocessd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def load_hdfs_graph_data(): \n",
    "    spark = SparkSession.builder \\\n",
    "    .appName(\"Router\") \\\n",
    "    .master(\"local\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "    stop_times_df =spark.read.parquet(\"../groupe-z/stop_times\").toPandas()\n",
    "    schema_walkable = StructType([\n",
    "        StructField(\"from_stop_id\", StringType(), nullable=True),\n",
    "        StructField(\"to_stop_id\", StringType(), nullable=True),\n",
    "        StructField(\"min_transfer_time\",FloatType(),nullable=True)\n",
    "        # Add more fields as needed\n",
    "    ])\n",
    "    df_walkable_pairs = spark.read.schema(schema_walkable).parquet(\"../groupe-z/walkable_transfers\").toPandas()\n",
    "    schema_dict = StructType([\n",
    "    StructField(\"stop_id\", StringType(), nullable=True),\n",
    "    StructField(\"stop_name\", StringType(), nullable=True),\n",
    "    StructField(\"stop_lat\", DoubleType(), nullable=True),\n",
    "    StructField(\"stop_lon\", DoubleType(), nullable=True),\n",
    "    StructField(\"location_type\", StringType(), nullable=True),\n",
    "    StructField(\"parent_station\", StringType(), nullable=True),\n",
    "    StructField(\"distance_to_zurich_hb\", DoubleType(), nullable=True),\n",
    "])\n",
    "\n",
    "    delays_df = spark.read.parquet(\"../groupe-z/delays\").toPandas()\n",
    "\n",
    "    return stop_times_df , df_walkable_pairs  , delays_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stop_times_df , df_walkable_pairs  ,delays_df = load_hdfs_graph_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local data\n",
    "id_to_name_dict  = pickle.load(open(\"../data/id_to_name_dict.pickle\",\"rb\"))\n",
    "\n",
    "name_to_id_dict  = pickle.load(open(\"../data/name_to_id_dict.pickle\",\"rb\"))\n",
    "\n",
    "stops_df = pickle.load(open(\"../data/stops_df.pickle\",\"rb\"))\n",
    "\n",
    "\n",
    "dict_walkable_pairs = {(row[\"from_stop_id\"],row[\"to_stop_id\"]):row[\"min_transfer_time\"] for _,row in df_walkable_pairs.iterrows()}\n",
    "\n",
    "code_to_type = {'walk': '', \n",
    "                'IC': 'Zug',\n",
    "                'IR': 'Zug',\n",
    "                'ICE': 'Zug',\n",
    "                'TGV': 'Zug',\n",
    "                'RE': 'Zug',\n",
    "                'NJ': 'Zug',\n",
    "                'RJX': 'Zug',\n",
    "                'B': 'Bus',\n",
    "                'T': 'Tram',\n",
    "                'FUN': 'Metro',\n",
    "                'BAT': '',\n",
    "                'FAE': '',\n",
    "                'S': 'Zug',\n",
    "                'EXT': '',\n",
    "                'FAE': '',\n",
    "                'EC': 'Zug',\n",
    "                'PB':'Bus'\n",
    "}\n",
    "\n",
    "\n",
    "# transform the data into an edge dataframe\n",
    "df_times = pd.DataFrame(stop_times_df[\"attr\"].to_list(), columns=['src_arrival_time','src_departure_time', 'dst_arrival_time', 'dst_departure_time'])\n",
    "df_edges = pd.concat([stop_times_df, df_times], axis=1)\n",
    "df_edges = df_edges.drop(columns=['attr','dst_departure_time'])\n",
    "df_w = df_walkable_pairs.rename(columns={\"from_stop_id\": \"src\", \"to_stop_id\": \"dst\",\"min_transfer_time\":\"dst_arrival_time\"})\n",
    "df_w[\"src_arrival_time\"] = -1\n",
    "df_w[\"src_departure_time\"] = 0\n",
    "df_w['trip_id'] = [i+1 for i in range(len(df_w))]\n",
    "df_edges = pd.concat([df_edges, df_w], axis=0)\n",
    "df_edges = df_edges.reset_index(drop=True)\n",
    "df_edges[\"travel_time\"] = df_edges[\"dst_arrival_time\"] - df_edges[\"src_departure_time\"]\n",
    "\n",
    "\n",
    "df_edges_grouped = df_edges.groupby(['src','dst',\"src_departure_time\",\"src_arrival_time\",\"dst_arrival_time\"]).agg(list).reset_index()\n",
    "df_edges_grouped[\"weight\"]= df_edges_grouped[\"travel_time\"].apply(lambda x: min(x))\n",
    "df_edges_grouped[\"num_trips\"]= df_edges_grouped[\"travel_time\"].apply(lambda x: len(x))\n",
    "df_edges_grouped[\"type\"]= df_edges_grouped[\"transport_type\"].apply(lambda x: x[0])\n",
    "df_edges_grouped[\"type\"]= df_edges_grouped[\"type\"].fillna(\"walk\")\n",
    "df_edges_grouped[\"trip_id\"]= df_edges_grouped[\"trip_id\"].apply(lambda x: x[0])\n",
    "df_edges_filtered = df_edges_grouped[df_edges_grouped[\"weight\"]>0][[\"src\",\"dst\",\"weight\",\"src_arrival_time\",\"src_departure_time\",\"dst_arrival_time\",\"type\",\"trip_id\"]]\n",
    "df_edges_filtered['type']  = df_edges_filtered['type'].apply(lambda x : code_to_type[x])\n",
    "df_edges_filtered.to_pickle(\"../data/df_edges_filtered.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sec(time_str):\n",
    "    \"\"\"Get seconds from time.\"\"\"\n",
    "    h, m, s = time_str.split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "def get_time(seconds):\n",
    "    \"\"\"Get time from seconds.\"\"\"\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return \"%02d:%02d:%02d\" % (h, m, s)\n",
    "def get_time_beautified(time_str):\n",
    "    h,m,s = time_str.split(\":\")\n",
    "    h,m,s=int(h),int(m),int(s)\n",
    "    hours_str = \"\" if h ==0 else (f\"{h}hr\")\n",
    "    minutes_str = \"\" if m == 0 else (f\"{m}min\")\n",
    "    return hours_str + minutes_str\n",
    "    \n",
    "    \n",
    "\n",
    "def walkable(src,dst):\n",
    "    return (src,dst) in dict_walkable_pairs.keys(), dict_walkable_pairs.get((src,dst),-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. find paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_potential_nodes(source, target, k):\n",
    "    G = nx.from_pandas_edgelist(df_edges_filtered, 'src', 'dst', ['weight'], create_using=nx.DiGraph())\n",
    "    paths = list(islice(nx.shortest_simple_paths(G, source, target, weight='weight'), k))\n",
    "    flat_list = list(set([item for sublist in paths for item in sublist]))\n",
    "    return flat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WAIT_TIME = 1800\n",
    "CONNECTION_WINDOW = 7200\n",
    "\n",
    "def find_actual_connections_arrival_time(start,end,desired_arrival_time,tolerance=1800,k=10,verbose=False):\n",
    "    print(\"finding potential stops\") if verbose else None\n",
    "    potential_nodes = find_potential_nodes(start,end,100)\n",
    "    pairs = [ (src,dst) for src in potential_nodes for dst in potential_nodes if src!=dst]\n",
    "    df_pairs = pd.DataFrame(pairs,columns=[\"src\",\"dst\"])\n",
    "    df_path = df_edges_filtered.merge(df_pairs,on=[\"src\",\"dst\"],how=\"inner\")\n",
    "    df_path = df_path[(df_path[\"type\"]!=\"walk\") & (df_path[\"src_arrival_time\"].apply(lambda x : abs(x - desired_arrival_time)<CONNECTION_WINDOW))]\n",
    "    df_path[\"connection_id\"] = range(len(df_path))\n",
    "\n",
    "    \n",
    "    ###################### 1. Create the graph ######################\n",
    "    H = nx.DiGraph()\n",
    "\n",
    "    print(\"adding nodes\") if verbose else None\n",
    "    #First, we add the nodes, each node corresponds to a connection between two stops\n",
    "    for stop in potential_nodes:\n",
    "        connections = df_path[(df_path[\"src\"]==stop)]\n",
    "        connections = connections[~connections.duplicated(subset=connections.columns.difference(['trip_id']))]\n",
    "        for _,row in connections.iterrows():\n",
    "            H.add_node(row[\"connection_id\"],src_arrival_time=row[\"src_arrival_time\"],src_departure_time=row[\"src_departure_time\"],dst_arrival_time=row[\"dst_arrival_time\"],weight=row[\"weight\"],src=row[\"src\"],dst=row[\"dst\"],type=row[\"type\"],trip_id=row['trip_id'])\n",
    "    #Then, we add the edges, an edge exists if it is possible to take a connection from one stop to another\n",
    "    print(\"adding edges\") if verbose else None\n",
    "    nodes = list(H.nodes(data=True))\n",
    "    for src_index, src_attr in nodes:\n",
    "        for dst_index,dst_attr in nodes:\n",
    "            if src_index == dst_index:\n",
    "                continue\n",
    "            if src_attr[\"dst\"] != dst_attr[\"src\"]: \n",
    "                is_walkable, walking_time = walkable(src_attr[\"dst\"], dst_attr[\"src\"])\n",
    "                is_connection_possible = (src_attr[\"dst_arrival_time\"] + walking_time < dst_attr[\"src_departure_time\"])\n",
    "                is_wait_not_too_long = (src_attr[\"dst_arrival_time\"] - src_attr[\"src_departure_time\"] < MAX_WAIT_TIME)\n",
    "                if (is_walkable and is_wait_not_too_long and is_connection_possible):\n",
    "                    H.add_edge(src_index,dst_index,weight=dst_attr[\"src_departure_time\"]-src_attr[\"src_departure_time\"])\n",
    "            else :\n",
    "                is_connection_possible = (src_attr[\"dst_arrival_time\"] < dst_attr[\"src_departure_time\"]) or (abs(src_attr[\"dst_arrival_time\"] - dst_attr[\"src_departure_time\"])<1)\n",
    "                is_wait_not_too_long =  (dst_attr[\"src_departure_time\"] - src_attr[\"dst_arrival_time\"] < MAX_WAIT_TIME)\n",
    "                if (is_connection_possible and is_wait_not_too_long):\n",
    "                    weight = dst_attr[\"src_departure_time\"] - src_attr[\"src_departure_time\"]\n",
    "                    H.add_edge(src_index,dst_index,weight=weight)\n",
    "                \n",
    "    #We add the end and start nodes, these will represent the start and end of the route ()\n",
    "    #This allows the route to start from any time \n",
    "    connections_from_start = [(node,attr) for node, attr in H.nodes(data=True) if (attr[\"src\"]==start or walkable(start,attr[\"src\"])[0])]\n",
    "    if len(connections_from_start) == 0:\n",
    "\n",
    "        print(\"no connections found for departure\") if verbose else None\n",
    "        return []\n",
    "    for node,attr in connections_from_start:\n",
    "        H.add_edge(\"start\",node,weight=0)\n",
    "\n",
    "    \n",
    "    #This allows the route to end only at the desired time, with a tolerance defined as a hyperparameter\n",
    "    connections_to_dest = [(node,attr) for node, attr in H.nodes(data=True) if node!=\"start\" and (attr[\"dst\"]==end or walkable(attr[\"dst\"],end)[0]) and (attr[\"dst_arrival_time\"] < desired_arrival_time) and (attr[\"dst_arrival_time\"] > (desired_arrival_time-tolerance))]\n",
    "    if len(connections_to_dest) == 0:\n",
    "        print(\"no connections found for destination\") if verbose else None\n",
    "        return []\n",
    "    for node,attr in connections_to_dest:\n",
    "        print(\"possible arrival time  from connection\", attr[\"dst\"],\"at\",get_time(attr[\"dst_arrival_time\"])) if verbose else None\n",
    "        if attr[\"dst\"] != end:\n",
    "            is_walkable, walking_time = walkable(attr[\"dst\"],end)\n",
    "            H.add_edge(node,\"end\",weight=walking_time)\n",
    "        else:\n",
    "            H.add_edge(node,\"end\",weight=attr[\"weight\"])\n",
    "\n",
    "\n",
    "    ###################### 2. Find the k shortest paths ######################\n",
    "    final_paths  = []\n",
    "    for _ in range(k):\n",
    "        if not nx.has_path(H,\"start\",\"end\"):\n",
    "            break\n",
    "        path = nx.shortest_path(H, \"start\", \"end\",weight=\"weight\")\n",
    "        res = path[1:-1]\n",
    "        departure_time = H.nodes[res[0]][\"src_departure_time\"]\n",
    "        arrival_time = H.nodes[res[-1]][\"dst_arrival_time\"]\n",
    "        print(\"departure_time\",get_time(departure_time)) if verbose else None\n",
    "        print(\"arrival_time\",get_time(arrival_time)) if verbose else None\n",
    "        print(\"total time spent\",get_time(arrival_time-departure_time)) if verbose else None\n",
    "        waypoints=[]\n",
    "        transport_order = 0\n",
    "        last_trip_id = H.nodes[res[0]][\"trip_id\"]\n",
    "        for waypoint in res:\n",
    "\n",
    "            src_departure_time = H.nodes[waypoint][\"src_departure_time\"]\n",
    "            dst_arrival_time = H.nodes[waypoint][\"dst_arrival_time\"]\n",
    "            src = H.nodes[waypoint][\"src\"]\n",
    "            dst = H.nodes[waypoint][\"dst\"]\n",
    "            type_ = H.nodes[waypoint][\"type\"]\n",
    "            trip_id = H.nodes[waypoint][\"trip_id\"]\n",
    "            src_name = id_to_name_dict[src] if (src in id_to_name_dict.keys()) else src\n",
    "            dst_name = id_to_name_dict[dst] if (dst in id_to_name_dict.keys()) else dst\n",
    "            if last_trip_id != trip_id:\n",
    "                transport_order +=1\n",
    "                last_trip_id=trip_id\n",
    "            w = {\"src_departure_time\":get_time(src_departure_time),\"dst_arrival_time\":get_time(dst_arrival_time),\"src\":src_name,\"dst\":dst_name,\"type\":type_,\"trip_id\":trip_id,\"src_id\":src,\"dst_id\":dst,\"transport_order\":transport_order}\n",
    "            print(w) if verbose else None\n",
    "            waypoints.append(w)\n",
    "        final_paths.append({\"departure_time\":get_time(departure_time),\"arrival_time\":get_time(arrival_time),\"travel_time\":arrival_time-departure_time,\"waypoints\":waypoints})\n",
    "        H.remove_edge(path[-2],path[-1])\n",
    "    return final_paths\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route (start,end, desired_arrival_time, verbose = False):\n",
    "    actual_paths = find_actual_connections_arrival_time(start,end,get_sec(desired_arrival_time),verbose=verbose)\n",
    "    print(\"sorting found paths\") if verbose else None\n",
    "    actual_paths = sorted(actual_paths,key=lambda x: get_sec(x[\"arrival_time\"]))\n",
    "    return actual_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 . Adding delays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted from notebook 02_calculating_delays\n",
    "AVG_DEP_DELAY = 108.6383003197186\n",
    "AVG_ARR_DELAY =  78.77420048977521\n",
    "\n",
    "STD_DEP_DELAY = 108.53734109482895\n",
    "STD_ARR_DELAY = 89.98687439461523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import scipy.integrate as integrate\n",
    "import numpy as np\n",
    "\n",
    "def compute_confidence(path, verbose=True): \n",
    "    \n",
    "    # create dataframe for the path\n",
    "    path_df = pd.DataFrame(path['waypoints'])\n",
    "    \n",
    "    display(path_df) if verbose else None\n",
    "    \n",
    "    # different trips\n",
    "    df_trips = path_df.groupby('trip_id').agg(list)\n",
    "    \n",
    "\n",
    "    df_trips['first'] = df_trips['src'].apply(lambda x: x[0])\n",
    "    df_trips['last'] = df_trips['dst'].apply(lambda x: x[-1])\n",
    "    df_trips['first_id'] = df_trips['src_id'].apply(lambda x: x[0])\n",
    "    df_trips['last_id'] = df_trips['dst_id'].apply(lambda x: x[-1])\n",
    "\n",
    "    df_trips['last_arrival_time'] = df_trips['dst_arrival_time'].apply(lambda x: x[-1])\n",
    "    df_trips['first_departure_time'] = df_trips['src_departure_time'].apply(lambda x: x[0])\n",
    "    df_trips['type'] = df_trips['type'].apply(lambda x : x[0])\n",
    "    df_trips = df_trips.sort_values(by='first_departure_time')\n",
    "    df_trips.reset_index(inplace=True)\n",
    "    \n",
    "   \n",
    "        # probability of not missing any connection\n",
    "    p_all = 1\n",
    "    connections_info = []\n",
    "    for i in range(len(df_trips)-1): \n",
    "        last_src_name = df_trips.iloc[i]['last']\n",
    "        first_dst_name = df_trips.iloc[i+1]['first']\n",
    "        last_src_id = df_trips.iloc[i]['last_id']\n",
    "        first_dst_id = df_trips.iloc[i+1]['first_id']\n",
    "        last_arrival_time = df_trips.iloc[i]['last_arrival_time']\n",
    "        first_departure_time = df_trips.iloc[i+1]['first_departure_time']\n",
    "        last_type = df_trips.iloc[i]['type']\n",
    "        first_type = df_trips.iloc[i+1]['type']\n",
    "        # convert time to datetime\n",
    "        last_arrival_time = pd.to_datetime(last_arrival_time, format='%H:%M:%S')\n",
    "        first_departure_time = pd.to_datetime(first_departure_time, format='%H:%M:%S')\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"\"\"********connection{i}*******\"\"\") if (verbose) else None\n",
    "        print(f\"\"\"from_name = {last_src_name}, to_name = {first_dst_name}, from={last_src_id}, to={first_dst_id}, start_time = {last_arrival_time}, deadline = {first_departure_time}\"\"\") if (verbose) else None\n",
    "\n",
    "        if last_src_name == first_dst_name: # NOT A WALK EDGE (simply train change)\n",
    "            delay_max = (first_departure_time - last_arrival_time).seconds\n",
    "            transfer = 0 \n",
    "        else : # a walk edge\n",
    "            has_transfer_time = len(df_walkable_pairs[(df_walkable_pairs['from_stop_id'] == last_src_id) & (df_walkable_pairs['to_stop_id'] == first_dst_id)]['min_transfer_time'].values) > 0\n",
    "            transfer = 0 if not has_transfer_time else df_walkable_pairs[(df_walkable_pairs['from_stop_id'] == last_src_id) & (df_walkable_pairs['to_stop_id'] == first_dst_id)]['min_transfer_time'].values[0]\n",
    "            print('transfer = ', transfer) if (verbose) else None\n",
    "            delay_max = (first_departure_time - last_arrival_time).seconds - transfer\n",
    "\n",
    "        print('delay_max = ', delay_max) if (verbose) else None\n",
    "\n",
    "               # get the delay of arrival for last stop of the first trip\n",
    "        has_arrival_delay_avg = len(delays_df[(delays_df['stop_name'] == last_src_name ) & (delays_df['transport_type'] == last_type) ]['avg_arr_delay'].values) > 0\n",
    "        last_arrival_delay_avg = pd.NA if not has_arrival_delay_avg else delays_df[(delays_df['stop_name'] == last_src_name ) & (delays_df['transport_type'] == last_type) ]['avg_arr_delay'].values[0]\n",
    "        last_arrival_delay_avg = last_arrival_delay_avg if not pd.isna(last_arrival_delay_avg) else AVG_ARR_DELAY\n",
    "\n",
    "        last_arrival_delay_stddev = pd.NA if not has_arrival_delay_avg else delays_df[(delays_df['stop_name'] == last_src_name ) & (delays_df['transport_type'] == last_type)]['stddev_arr_delay'].values[0]\n",
    "        last_arrival_delay_stddev = last_arrival_delay_stddev if not pd.isna(last_arrival_delay_stddev) else STD_ARR_DELAY\n",
    "\n",
    "        # get the delay of departure for the first stop of the second trip\n",
    "        first_departure_delay_avg = pd.NA if not has_arrival_delay_avg else  delays_df[(delays_df['stop_name'] == first_dst_name ) & (delays_df['transport_type'] == first_type)]['avg_dep_delay'].values[0]\n",
    "        first_departure_delay_avg = first_departure_delay_avg if not pd.isna(first_departure_delay_avg) else AVG_DEP_DELAY\n",
    "\n",
    "        first_departure_delay_stddev =  pd.NA if not has_arrival_delay_avg else delays_df[(delays_df['stop_name'] == first_dst_name ) & (delays_df['transport_type'] == first_type)]['stddev_dep_delay'].values[0]\n",
    "        first_departure_delay_stddev = first_departure_delay_stddev if not pd.isna(first_departure_delay_stddev) else STD_DEP_DELAY\n",
    "\n",
    "\n",
    "\n",
    "        ### METHOD 1 : using the probability of delay > delay_max\n",
    "        # probability of delay > delay_max\n",
    "        p = 1 - stats.norm.cdf(delay_max, last_arrival_delay_avg, last_arrival_delay_stddev)\n",
    "        print('average_delay = ', last_arrival_delay_avg) if (verbose) else None\n",
    "        print('stddev_delay = ', last_arrival_delay_stddev) if (verbose) else None\n",
    "        print('p = ', p) if (verbose) else None\n",
    "\n",
    "\n",
    "        ### METHOD 2 : using the probability of delay > delay_max-y knowing y (y is the delay of departure of the second trip)\n",
    "        # Define the integrand function for p_sachant\n",
    "        def integrand(delay_dep):\n",
    "            p_dep = stats.norm.pdf(delay_dep, first_departure_delay_avg, first_departure_delay_stddev)\n",
    "            return (1 - stats.norm.cdf(delay_max + delay_dep, last_arrival_delay_avg, last_arrival_delay_stddev)) * p_dep\n",
    "\n",
    "        p_sachant, _ = integrate.quad(integrand, -np.inf, np.inf)  \n",
    "        print('p sachant = ', p_sachant) if (verbose) else None\n",
    "        \n",
    "        connections_info.append({'proba_miss' : p_sachant , 'src' : last_src_name , 'dst': first_dst_name , 'transfer_time' : transfer , 'rank_con' : i })\n",
    "\n",
    "\n",
    "        # print general info\n",
    "        print('probability of missing this connection = ', p_sachant) if (verbose) else None\n",
    "\n",
    "        p_all = (1 - p_sachant) * p_all\n",
    "\n",
    "    print('probability of not missing any connection = ', p_all) if (verbose) else None\n",
    "    \n",
    "    return p_all , connections_info\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_delays(paths,verbose=False):\n",
    "    for i,path  in enumerate(paths) : \n",
    "\n",
    "        proba, info = compute_confidence(path,verbose=verbose)\n",
    "\n",
    "        path['confidence'] = proba\n",
    "        path['confidence_info'] = info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(journey,i):\n",
    "    colors = [\"yellow\",\"red\",\"white\",\"green\",\"purple\",\"orange\",\n",
    "          \"blue\",  \n",
    "          \"brown\",\n",
    "            \"cyan\",\n",
    "            \"navy\",\n",
    "            \"linen\",\n",
    "            \"tomato\",\n",
    "            \"olive\",\n",
    "            \"lime\",\n",
    "            \"greenyellow\"]\n",
    "    j_dep_time = journey['departure_time']\n",
    "    j_arr_time = journey['arrival_time']\n",
    "    j_duration = get_time(journey['travel_time'])\n",
    "    waypoints = journey['waypoints']\n",
    "\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame.from_records(waypoints)\n",
    "    #add long and lat\n",
    "    df[\"src_lon\"] = df.merge(stops_df,left_on=\"src_id\",right_on=\"stop_id\")[\"stop_lon\"]\n",
    "    df[\"src_lat\"] = df.merge(stops_df,left_on=\"src_id\",right_on=\"stop_id\")[\"stop_lat\"]\n",
    "    df[\"dst_lon\"] = df.merge(stops_df,left_on=\"dst_id\",right_on=\"stop_id\")[\"stop_lon\"]\n",
    "    df[\"dst_lat\"] = df.merge(stops_df,left_on=\"dst_id\",right_on=\"stop_id\")[\"stop_lat\"]\n",
    "    \n",
    "    last_row = df.iloc[-1]\n",
    "    first_row = df.iloc[0]\n",
    "    dst_lon,dst_lat,dst_name, = last_row[\"dst_lon\"],last_row[\"dst_lat\"],last_row[\"dst\"]\n",
    "    src_lon,src_lat = first_row[\"src_lon\"],first_row[\"src_lat\"]\n",
    "    orders = sorted(df[\"transport_order\"].unique())\n",
    "    \n",
    "    \n",
    "        # l is the layout of the plot, we use to set the title, the margins and the style of the map\n",
    "    l = go.Layout(\n",
    "        title= f'Journey {i+1}: Departure: {j_dep_time} Arrival: {j_arr_time}', \n",
    "        margin ={'l':0,'t':100,'b':0,'r':0},\n",
    "        mapbox = {\n",
    "            'style': \"open-street-map\",\n",
    "            'center': {'lon':(dst_lon+src_lon)/2 , 'lat': (dst_lat+src_lat)/2},\n",
    "            'zoom': 9,},\n",
    "        title_x = 0.41\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(go.Scattermapbox(\n",
    "            mode = \"markers+lines\",\n",
    "            marker = {'size': 10},\n",
    "            ), l)\n",
    "    \n",
    "    \n",
    "    for _,row in df.iterrows():\n",
    "        fig.add_trace(go.Scattermapbox(mode='lines',\n",
    "                                   lon=[row['src_lon'], row['dst_lon']],\n",
    "                                   lat=[row['src_lat'], row['dst_lat']],\n",
    "                                   line_color=colors[row[\"transport_order\"]],\n",
    "                                   name=row['dst'] \n",
    "        ))  \n",
    "\n",
    "    fig.add_trace(go.Scattermapbox(mode = \"markers\",\n",
    "                                    lon = df[\"src_lon\"].append(pd.Series([dst_lon])),\n",
    "                                    lat = df[\"src_lat\"].append(pd.Series([dst_lat])),\n",
    "                                    text= df[\"src\"].append(pd.Series([dst_name])),\n",
    "                                    customdata=df[\"src_departure_time\"].append(pd.Series([\"\"])),\n",
    "                                    showlegend=False,\n",
    "                                    marker = {'size': 12,'color': \"black\"},\n",
    "                                    hovertemplate=\"<br>\".join([\n",
    "    \"Station name: %{text}\",\"Depature time: %{customdata}\"])))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_paths_accordion(journeys):\n",
    "    titles=[]\n",
    "    children =[]\n",
    "    \n",
    "    for i,journey in enumerate(journeys):\n",
    "        j_dep_time = journey['departure_time']\n",
    "        j_arr_time = journey['arrival_time']\n",
    "        j_duration = get_time(journey['travel_time'])\n",
    "        j_confidence = journey.get(\"confidence\")\n",
    "        j_confidence_info = journey.get(\"confidence_info\")\n",
    "        titles.append(f\"{j_dep_time[:-3]}  =====> {j_arr_time[:-3]} \\t\\t\\t\\t\\t\\t{get_time_beautified(j_duration)} \\t\\t\\t\\t\\t\\t Q: {(j_confidence*100):.2f}%\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        transfers_labels = []\n",
    "        transfers_labels.append(widgets.Label(value=f\"There {'is' if len(j_confidence_info) == 1 else 'are'} {len(j_confidence_info)} transfer{'' if len(j_confidence_info) == 1 else 's' } for this trip\"))\n",
    "        for transfer in j_confidence_info:\n",
    "            transfers_labels.append(widgets.Label(value=f\"\\t- You have a probabiltiy of {(100*transfer['proba_miss']):.2f}% of missing your connection between {transfer['src']} and {transfer['dst']}\"))\n",
    "        \n",
    "        children.append(widgets.VBox(transfers_labels))\n",
    "        \n",
    "    accordion = widgets.Accordion(children=children, titles=titles)\n",
    "    return accordion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we define all the widgets\n",
    "import datetime\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "time_picker = widgets.TimePicker(\n",
    "    description='Pick a Time',\n",
    "    value= datetime.datetime.strptime(\"10:00\", '%H:%M'),\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "departure_station = widgets.Combobox(\n",
    "    value= \"Hausen am Albis, Riedmatt\",\n",
    "    placeholder='Type station name',\n",
    "    options=list(name_to_id_dict.keys()),\n",
    "    description='Departure Station:',\n",
    "    ensure_option=True,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "arrival_station = widgets.Combobox(\n",
    "    value = \"ZÃ¼rich Flughafen\",\n",
    "    placeholder='Type station name',\n",
    "    options=list(name_to_id_dict.keys()),\n",
    "    description='Arrival Station:',\n",
    "    ensure_option=True,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "layout = widgets.Layout(width='auto', height='50px')\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Find route',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click this button',\n",
    "    icon='search', # (FontAwesome names without the `fa-` prefix)\n",
    "    layout = layout\n",
    ")\n",
    "\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "# The following functions defines what happens when we press the button\n",
    "\n",
    "                             \n",
    "def button_action(button):\n",
    "    \n",
    "    out.clear_output()   # each time we press the button we clear the previous output\n",
    "    \n",
    "    with out:\n",
    "\n",
    "        dep_station_id = name_to_id_dict.get(departure_station.value)\n",
    "        arr_station_id = name_to_id_dict.get(arrival_station.value)\n",
    "                \n",
    "        if dep_station_id is None or arr_station_id is None:\n",
    "            print(\"You need to select a start and destination\", file=sys.stderr)\n",
    "            return\n",
    "        if dep_station_id == arr_station_id:\n",
    "            print(\"Start and end station shoud not be the same\", file=sys.stderr)\n",
    "            return\n",
    "        \n",
    "        time_picker_string = time_picker.value\n",
    "        if time_picker_string is None:\n",
    "            print(\"You must choose an arrival time\", file=sys.stderr)\n",
    "            return\n",
    "        desired_arrival_time = (time_picker_string.strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "        \n",
    "        progress_bar = widgets.FloatProgress(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=10.0,\n",
    "            description='Starting...',\n",
    "            bar_style='info',\n",
    "            orientation='horizontal'\n",
    "        )\n",
    "        display(progress_bar)\n",
    "        \n",
    "        progress_bar.value = 5\n",
    "        progress_bar.description = \"Calculating paths\"\n",
    "        paths = route(dep_station_id,arr_station_id,desired_arrival_time)\n",
    "        \n",
    "        # keep only distinct routes\n",
    "        \n",
    "        if len(paths) == 0:\n",
    "            print(\"No paths found\", file=sys.stderr)\n",
    "            return\n",
    "        progress_bar.value = 7\n",
    "        progress_bar.description = \"Adding delays\"\n",
    "        add_delays(paths,verbose=False)\n",
    "        \n",
    "        progress_bar.value = 8\n",
    "        progress_bar.description = \"Creating maps\"\n",
    "        \n",
    "        maps = [create_map(path,i) for (i,path) in enumerate(paths)]\n",
    "        \n",
    "        output_maps = widgets.Output()\n",
    "        accordion = build_paths_accordion(paths)\n",
    "\n",
    "        def accordion_eventhandler(change):\n",
    "            with output_maps:\n",
    "                clear_output()\n",
    "                i = change.new\n",
    "                if i is not None:\n",
    "                    display(maps[i])\n",
    "        accordion.observe(accordion_eventhandler, names='selected_index')\n",
    "\n",
    "        # Display the dropdown widget and initial figure\n",
    "        display(accordion)\n",
    "        display(output_maps)\n",
    "        \n",
    "        progress_bar.value = 10\n",
    "        progress_bar.description = \"Done!\"\n",
    "        \n",
    "        \n",
    "button.on_click(button_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e414a2fd58454724a4822e46d01dbe90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TimePicker(value=datetime.datetime(1900, 1, 1, 10, 0), description='Pick a Time', step=60.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafd9ca7dd7f4fa0b5fa0c2257cea88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Combobox(value='Hausen am Albis, Riedmatt', description='Departure Station:', ensure_option=True, options=('Oeâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9784ddc2f44d0689649dc758863fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Combobox(value='ZÃ¼rich Flughafen', description='Arrival Station:', ensure_option=True, options=('Oetwil a.d.L.â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16ef79eb176483d858bdad337e7716f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Find route', icon='search', layout=Layout(height='50px', width='auto'), style=ButtonStyle(â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5166b36d297c461dab3e5a567ac9b95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(time_picker , departure_station, arrival_station, button, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
